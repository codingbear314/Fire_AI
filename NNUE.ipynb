{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Dense, self).__init__()\n",
    "        uniform_range = 1.0 / input_size\n",
    "        uniform_distribution = torch.distributions.uniform.Uniform(-uniform_range, uniform_range)\n",
    "        self.Weights = nn.Parameter(uniform_distribution.sample((input_size, output_size)))\n",
    "        self.Bias = nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.Weights) + self.Bias\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'''\n",
    "Dense Layer\n",
    "input size : {self.Weights.size(0)}, output size : {self.Weights.size(1)}\n",
    "Weights :\n",
    "{self.Weights}\n",
    "Bias :\n",
    "{self.Bias}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNUE_V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNUE_V1, self).__init__()\n",
    "\n",
    "        self.ProcessPlayer = Dense(41024, 256)\n",
    "\n",
    "        self.FirstDense = Dense(512, 32)\n",
    "        self.SecondDense = Dense(32, 32)\n",
    "        self.Output = Dense(32, 1)\n",
    "\n",
    "        self.Activation = torch.relu\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x dimentions : batch x 2 x 41024\n",
    "        FirstToPlay  = self.Activation(self.ProcessPlayer(x[:, 0, :])) # batch x 256\n",
    "        SecondToPlay = self.Activation(self.ProcessPlayer(x[:, 1, :])) # batch x 256\n",
    "\n",
    "        x = torch.cat((FirstToPlay, SecondToPlay), dim=1)\n",
    "        \n",
    "        x = self.Activation(self.FirstDense(x))\n",
    "        x = self.Activation(self.SecondDense(x))\n",
    "        x = self.Output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_str: str):\n",
    "    parts = encoded_str.split()\n",
    "    evaluation = int(parts[-1])\n",
    "    tensor = torch.zeros((6, 8, 8), dtype=torch.int)\n",
    "\n",
    "    def decode_layer(encoded_value, sign):\n",
    "        decoded_layer = torch.zeros((8, 8), dtype=torch.int)\n",
    "        for j in range(64):\n",
    "            if encoded_value & (1 << (63 - j)):\n",
    "                decoded_layer[j // 8, j % 8] = sign\n",
    "        return decoded_layer\n",
    "\n",
    "    for i in range(6):\n",
    "        for sign in [-1, 1]:\n",
    "            encoded_value = int(parts[2 * i + (sign == -1)])\n",
    "            tensor[i] += decode_layer(encoded_value, sign)\n",
    "\n",
    "    return tensor, evaluation\n",
    "\n",
    "def decode_2(encoded_str: str):\n",
    "    ret = torch.zeros(2, 41024)\n",
    "\n",
    "    tnsr, eval = decode(encoded_str)\n",
    "\n",
    "    # First to move\n",
    "    King_Type_Cord = torch.zeros(64, 10, 64)\n",
    "\n",
    "    # Find King\n",
    "    king1 = -1\n",
    "    for i in range(64):\n",
    "        if tnsr[5, i // 8, i % 8] == 1:\n",
    "            king1 = i\n",
    "            break\n",
    "    \n",
    "    # For every piece square\n",
    "    for i in range(64):\n",
    "        for j in range(10):\n",
    "            sign = 0\n",
    "            if j % 2 == 0 :\n",
    "                sign = 1\n",
    "            else:\n",
    "                sign = -1\n",
    "            idx = (j+2)//2\n",
    "            if tnsr[idx, i // 8, i % 8] == sign:\n",
    "                King_Type_Cord[king1, j, i] = 1\n",
    "    \n",
    "    # Find enemy king\n",
    "    king2 = -1\n",
    "    for i in range(64):\n",
    "        if tnsr[5, i // 8, i % 8] == -1:\n",
    "            king2 = i\n",
    "            break\n",
    "    \n",
    "    Additional = torch.zeros(64)\n",
    "    Additional[king2] = 1\n",
    "\n",
    "    ret[0] = torch.cat((King_Type_Cord.view(64*10*64), Additional.view(64)))\n",
    "\n",
    "    # Second to move\n",
    "    King_Type_Cord = torch.zeros(64, 10, 64)\n",
    "    # For every piece square\n",
    "    for i in range(64):\n",
    "        for j in range(10):\n",
    "            sign = 0\n",
    "            if j % 2 == 0 :\n",
    "                sign = -1\n",
    "            else:\n",
    "                sign = 1\n",
    "            idx = (j+2)//2\n",
    "            if tnsr[idx, i // 8, i % 8] == sign:\n",
    "                King_Type_Cord[king1, j, i] = 1\n",
    "\n",
    "    Additional = torch.zeros(64)\n",
    "    Additional[king1] = 1\n",
    "    \n",
    "    ret[1] = torch.cat((King_Type_Cord.view(64*10*64), Additional.view(64)))\n",
    "\n",
    "    return ret, torch.tensor([eval])\n",
    "    \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.path = file_path\n",
    "        self.file = open(file_path)\n",
    "        self.lines = self.file.readlines()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # output : 2 x 41024\n",
    "        line = self.lines[idx]\n",
    "        tnr, eval = decode_2(line)\n",
    "        return tnr, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import torch\n",
    "\n",
    "def board_to_tensor(board):\n",
    "    tensor = torch.zeros(6, 8, 8)\n",
    "    for file in range(8):\n",
    "        for rank in range(8):\n",
    "            square = chess.square(file, rank)\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                piecet = piece.piece_type\n",
    "                number = 1 if piece.color == chess.WHITE else -1\n",
    "                tensor[int(piecet)-1, file, rank] = number\n",
    "    return tensor\n",
    "\n",
    "INIT_BOARD = board_to_tensor(chess.Board())\n",
    "\n",
    "class TensorBoard:\n",
    "    def __init__(self):\n",
    "        self.board = chess.Board()\n",
    "        self.tensor = INIT_BOARD.clone()\n",
    "\n",
    "    def push(self, move: chess.Move):\n",
    "        # Get the piece type and color\n",
    "        from_square = move.from_square\n",
    "        to_square = move.to_square\n",
    "        piece = self.board.piece_at(from_square)\n",
    "        piecet = piece.piece_type\n",
    "        color = 1 if piece.color == chess.WHITE else -1\n",
    "\n",
    "        # Clear the 'from' square\n",
    "        from_file, from_rank = chess.square_file(from_square), chess.square_rank(from_square)\n",
    "        self.tensor[:, from_file, from_rank] = 0\n",
    "\n",
    "        # Set the 'to' square\n",
    "        to_file, to_rank = chess.square_file(to_square), chess.square_rank(to_square)\n",
    "        self.tensor[:, to_file, to_rank] = 0  # Clear any captured piece\n",
    "        self.tensor[int(piecet)-1, to_file, to_rank] = color\n",
    "\n",
    "        # Handle special moves\n",
    "        if self.board.is_castling(move):\n",
    "            if to_file > from_file:  # Kingside castling\n",
    "                rook_from, rook_to = chess.H1 if color == 1 else chess.H8, chess.F1 if color == 1 else chess.F8\n",
    "            else:  # Queenside castling\n",
    "                rook_from, rook_to = chess.A1 if color == 1 else chess.A8, chess.D1 if color == 1 else chess.D8\n",
    "            rook_from_file, rook_from_rank = chess.square_file(rook_from), chess.square_rank(rook_from)\n",
    "            rook_to_file, rook_to_rank = chess.square_file(rook_to), chess.square_rank(rook_to)\n",
    "            self.tensor[int(chess.ROOK)-1, rook_from_file, rook_from_rank] = 0\n",
    "            self.tensor[int(chess.ROOK)-1, rook_to_file, rook_to_rank] = color\n",
    "        elif self.board.is_en_passant(move):\n",
    "            captured_pawn = chess.square(to_file, from_rank)\n",
    "            captured_file, captured_rank = chess.square_file(captured_pawn), chess.square_rank(captured_pawn)\n",
    "            self.tensor[int(chess.PAWN)-1, captured_file, captured_rank] = 0\n",
    "        elif move.promotion:\n",
    "            self.tensor[int(piecet)-1, to_file, to_rank] = 0\n",
    "            self.tensor[int(move.promotion)-1, to_file, to_rank] = color\n",
    "\n",
    "        # Update the underlying chess board\n",
    "        self.board.push(move)\n",
    "\n",
    "\n",
    "    def pop(self):\n",
    "        move = self.board.pop()\n",
    "        \n",
    "        # Reverse the move\n",
    "        from_square = move.to_square\n",
    "        to_square = move.from_square\n",
    "        piece = self.board.piece_at(to_square)\n",
    "        piecet = piece.piece_type\n",
    "        color = 1 if piece.color == chess.WHITE else -1\n",
    "\n",
    "        # Clear the 'from' square (which was the 'to' square in the original move)\n",
    "        from_file, from_rank = chess.square_file(from_square), chess.square_rank(from_square)\n",
    "        self.tensor[:, from_file, from_rank] = 0\n",
    "\n",
    "        # Set the 'to' square (which was the 'from' square in the original move)\n",
    "        to_file, to_rank = chess.square_file(to_square), chess.square_rank(to_square)\n",
    "        self.tensor[int(piecet)-1, to_file, to_rank] = color\n",
    "\n",
    "        # Handle special moves\n",
    "        if self.board.is_castling(move):\n",
    "            if from_file > to_file:  # Kingside castling\n",
    "                rook_to, rook_from = chess.H1 if color == 1 else chess.H8, chess.F1 if color == 1 else chess.F8\n",
    "            else:  # Queenside castling\n",
    "                rook_to, rook_from = chess.A1 if color == 1 else chess.A8, chess.D1 if color == 1 else chess.D8\n",
    "            rook_to_file, rook_to_rank = chess.square_file(rook_to), chess.square_rank(rook_to)\n",
    "            rook_from_file, rook_from_rank = chess.square_file(rook_from), chess.square_rank(rook_from)\n",
    "            self.tensor[int(chess.ROOK)-1, rook_to_file, rook_to_rank] = 0\n",
    "            self.tensor[int(chess.ROOK)-1, rook_from_file, rook_from_rank] = color\n",
    "        elif self.board.is_en_passant(move):\n",
    "            captured_pawn = chess.square(from_file, to_rank)\n",
    "            captured_file, captured_rank = chess.square_file(captured_pawn), chess.square_rank(captured_pawn)\n",
    "            self.tensor[int(chess.PAWN)-1, captured_file, captured_rank] = -color\n",
    "        elif move.promotion:\n",
    "            self.tensor[int(move.promotion)-1, from_file, from_rank] = 0\n",
    "            self.tensor[int(chess.PAWN)-1, to_file, to_rank] = color\n",
    "\n",
    "        # If a piece was captured, restore it\n",
    "        captured_piece = self.board.piece_at(from_square)\n",
    "        if captured_piece:\n",
    "            captured_piecet = captured_piece.piece_type\n",
    "            captured_color = 1 if captured_piece.color == chess.WHITE else -1\n",
    "            self.tensor[int(captured_piecet)-1, from_file, from_rank] = captured_color\n",
    "\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encode(tb : TensorBoard, evaluation : float):\n",
    "    encoded = ''\n",
    "    tnr = tb.tensor\n",
    "    if tb.board.turn == chess.BLACK:\n",
    "        tnr = -tnr\n",
    "        evaluation = -evaluation\n",
    "    for i in range(6):\n",
    "        for sign in [-1, 1]:\n",
    "            int_ = 0\n",
    "            for j in range(64):\n",
    "                if tnr[i, j//8, j%8] == sign:\n",
    "                    int_ = 2*int_ + 1\n",
    "                else:\n",
    "                    int_ = 2*int_\n",
    "            encoded += str(int_) + ' '\n",
    "    \n",
    "    return encoded+str(int(100*evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144680345776816642 4629771060831600704 281474976710912 36028797018996736 1099511693312 140737496743936 72057594037927937 9223372036854775936 4294967296 549755813888 16777216 2147483648 0\n"
     ]
    }
   ],
   "source": [
    "TB = TensorBoard()\n",
    "TB.push(chess.Move.from_uci('e2e4'))\n",
    "TB.push(chess.Move.from_uci('e7e5'))\n",
    "\n",
    "print(Encode(TB, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Number of parameters : 10519905\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'TextIOWrapper' instances",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m, in \u001b[0;36mTrain\u001b[1;34m(epochs, Dataloader_Train, Dataloader_Test, model, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      7\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (tnr, \u001b[38;5;28meval\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDataloader_Train\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     10\u001b[0m     tnr, \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m tnr\u001b[38;5;241m.\u001b[39mto(device), \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\js314\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'TextIOWrapper' instances"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "def Train(epochs, Dataloader_Train, Dataloader_Test, model, criterion, optimizer, device):\n",
    "    lowest_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i, (tnr, eval) in enumerate(Dataloader_Train):\n",
    "            tnr, eval = tnr.to(device), eval.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(tnr)\n",
    "            loss = criterion(output, eval)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * tnr.size(0)\n",
    "        \n",
    "        train_loss /= len(Dataloader_Train.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.inference_mode():\n",
    "            for i, (tnr, eval) in enumerate(Dataloader_Test):\n",
    "                tnr, eval = tnr.to(device), eval.to(device)\n",
    "                output = model(tnr)\n",
    "                loss = criterion(output, eval)\n",
    "                test_loss += loss.item() * tnr.size(0)\n",
    "        \n",
    "        test_loss /= len(Dataloader_Test.dataset)\n",
    "\n",
    "        print(f'Epoch : {epoch+1}/{epochs} Train Loss : {train_loss}, Test Loss : {test_loss}')\n",
    "\n",
    "        if test_loss < lowest_loss:\n",
    "            lowest_loss = test_loss\n",
    "            torch.save(model.state_dict(), '../Model/NNUE_V1_best.pt')\n",
    "            print('Model saved')\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = NNUE_V1().to(device)\n",
    "\n",
    "    num_gpu = torch.cuda.device_count()\n",
    "    if num_gpu > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    print(f'Training on {device}')\n",
    "    print(f'Number of parameters : {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "\n",
    "    # Load the model\n",
    "    # model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = Dataset('../Dataset/Processed/Dataset_V1.txt')\n",
    "\n",
    "    # Divide the dataset into training set and validation set\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Define the dataloaders\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    Train(100, train_dataloader, test_dataloader, model, criterion, optimizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
